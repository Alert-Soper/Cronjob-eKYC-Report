name: Daily PromQL Report via Grafana

on:
  schedule:
    - cron: '30 1 * * *'  # ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 09:00 UTC (16:00 ‡∏ô. ‡πÑ‡∏ó‡∏¢)
  push:
    branches:
      - main
  workflow_dispatch:

env:
  GRAFANA_URL: 'http://122.8.149.46:8088/'
  DATASOURCE_UID: 'beao6gxdgw740f'  # UID ‡∏Ç‡∏≠‡∏á Prometheus Data Source ‡πÉ‡∏ô Grafana
  LINE_GROUP_ID: 'Cd28550496fd213d14a4b8aa42f5215b6'

jobs:
  generate-and-send-report:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests python-dotenv

    - name: Query and send report
      env:
        GRAFANA_TOKEN: ${{ secrets.GRAFANA_TOKEN }}
        LINE_CHANNEL_ACCESS_TOKEN: ${{ secrets.LINE_CHANNEL_ACCESS_TOKEN }}
      run: |
        python - << 'EOF'
        import os
        import requests
        import json
        from datetime import datetime, timedelta

        grafana_url = os.environ["GRAFANA_URL"]
        headers = {
            "Authorization": f"Bearer {os.environ['GRAFANA_TOKEN']}",
            "Content-Type": "application/json"
        }

        job_name = "thinker-gw"
        time_range = "1d"
        time_r = "7d"

        queries = {
            "success_rate": f'''
            100 * (
                sum(rate(http_requests_total{{job="{job_name}", status=~"2.."}}[{time_range}]))
                /
                sum(rate(http_requests_total{{job="{job_name}"}}[{time_range}]))
            )
            ''',
            "api_errors": f'''
            sum(rate(http_requests_total{{job="{job_name}", status=~"5.."}}[{time_range}]))
            ''',
            "daily_attempts": f'''
            sum(increase(http_requests_total{{job="{job_name}"}}[{time_range}]))
            ''',
            "weekly_attempts": f'''
            sum(increase(http_requests_total{{job="{job_name}"}}[{time_r}]))
            '''
        }

        def query_prometheus_via_grafana(query):
            now = datetime.now()
            yesterday = now - timedelta(days=1)
            params = {
                "query": query,
                "start": yesterday.timestamp(),
                "end": now.timestamp(),
                "step": "1h"
            }
            response = requests.get(
                f"{grafana_url}/api/datasources/proxy/{os.environ['DATASOURCE_UID']}/api/v1/query_range",
                headers=headers,
                params=params
            )
            return response.json()

        def process_results(results):
            metrics = {}

            if 'success_rate' in results:
                try:
                    if results['success_rate']['data']['resultType'] == 'scalar':
                        metrics['success_rate'] = float(results['success_rate']['data']['result'][1])
                    elif results['success_rate']['data']['resultType'] == 'matrix':
                        values = [float(x[1]) for x in results['success_rate']['data']['result'][0]['values']]
                        metrics['success_rate'] = sum(values) / len(values)
                except (KeyError, IndexError, TypeError) as e:
                    print(f"Error processing success_rate: {e}")
                    metrics['success_rate'] = 0.0

            if 'api_errors' in results:
                try:
                    if results['api_errors']['data']['resultType'] == 'scalar':
                        metrics['api_errors'] = float(results['api_errors']['data']['result'][1])
                    elif results['api_errors']['data']['resultType'] == 'matrix':
                        metrics['api_errors'] = sum(
                            float(x[1]) for x in results['api_errors']['data']['result'][0]['values']
                        )
                except (KeyError, IndexError, TypeError) as e:
                    print(f"Error processing api_errors: {e}")
                    metrics['api_errors'] = 0.0

            if 'daily_attempts' in results:
                try:
                    if results['daily_attempts']['data']['resultType'] == 'scalar':
                        metrics['daily_attempts'] = float(results['daily_attempts']['data']['result'][1])
                    elif results['daily_attempts']['data']['resultType'] == 'matrix':
                        metrics['daily_attempts'] = sum(
                            float(x[1]) for x in results['daily_attempts']['data']['result'][0]['values']
                        )
                except (KeyError, IndexError, TypeError) as e:
                    print(f"Error processing daily_attempts: {e}")
                    metrics['daily_attempts'] = 0.0

            if 'weekly_attempts' in results:
                try:
                    if results['weekly_attempts']['data']['resultType'] == 'scalar':
                        metrics['weekly_attempts'] = float(results['weekly_attempts']['data']['result'][1])
                    elif results['weekly_attempts']['data']['resultType'] == 'matrix':
                        metrics['weekly_attempts'] = sum(
                            float(x[1]) for x in results['weekly_attempts']['data']['result'][0]['values']
                        )
                except (KeyError, IndexError, TypeError) as e:
                    print(f"Error processing weekly_attempts: {e}")
                    metrics['weekly_attempts'] = 0.0

            return metrics

        results = {}
        for name, query in queries.items():
            results[name] = query_prometheus_via_grafana(query)

        print("Raw results for debugging:")
        print(json.dumps(results, indent=2))

        metrics = process_results(results)

        if metrics:
            report = [
                "üìä ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô (via PromQL)",
                f"‚è∞ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {datetime.now().strftime('%Y-%m-%d')}",
                "",
                f"‚úÖ Success Rate: {metrics.get('success_rate', 0):.2f}%",
                f"‚ùå Error Rate: {100 - metrics.get('success_rate', 0):.2f}%",
                "",
                f"üî• API Errors: {metrics.get('api_errors', 0):,.0f} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                "",
                f"üìà Attempts ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ: {metrics.get('daily_attempts', 0):,.0f} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                f"üìÖ Attempts 7 ‡∏ß‡∏±‡∏ô: {metrics.get('weekly_attempts', 0):,.0f} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
            ]

            message = {
                "to": os.environ["LINE_GROUP_ID"],
                "messages": [{
                    "type": "text",
                    "text": "\n".join(report)
                }]
            }

            response = requests.post(
                'https://api.line.me/v2/bot/message/push',
                headers={'Authorization': f'Bearer {os.environ["LINE_CHANNEL_ACCESS_TOKEN"]}'},
                json=message
            )
            print("‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        else:
            print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")
        EOF
